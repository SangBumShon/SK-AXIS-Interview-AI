# app/services/pipeline/graph_pipeline.py

from langgraph.graph import StateGraph
from datetime import datetime
import os
import asyncio

# ì„œë¹„ìŠ¤ í•¨ìˆ˜ ì„í¬íŠ¸
from app.services.interview.stt_service import transcribe_audio_file
from app.services.interview.rewrite_service import rewrite_answer
from app.services.interview.evaluation_service import evaluate_keywords_from_full_answer
from app.services.interview.report_service import create_radar_chart, generate_pdf


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ìƒíƒœ(state) êµ¬ì¡° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ê° ì—ì´ì „íŠ¸/ë…¸ë“œ í˜¸ì¶œ ì‹œ ì¸ìë¡œ ì „ë‹¬ë©ë‹ˆë‹¤.
# ì§€ì›ì ë‹¨ìœ„ë¡œ ë…ë¦½ ì‹¤í–‰ ê°€ëŠ¥í•˜ë„ë¡ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤.
#
# state = {
#     "interviewee_id": str,                      # ì§€ì›ì ID
#     "interview_ended": bool,                    # ë©´ì ‘ ì¢…ë£Œ ì—¬ë¶€
#     "questions": List[str],                     # StartInterview ì‹œ ì£¼ì…

#     "stt": {
#         "segments": [                           # ëˆ„ì ëœ STT ê²°ê³¼ ëª©ë¡
#             {
#                 "raw": str,                     # ì›ë¬¸ ì „ì‚¬ í…ìŠ¤íŠ¸
#                 "timestamp": str                # ë°œí™” ì‹œì  (ì„ íƒì‚¬í•­: "00:01:23")
#               }
#         ]
#     },

#     "rewrite": {
#         "done": bool,                           # ì „ì²´ ë¦¬ë¼ì´íŒ… ì¢…ë£Œ ì—¬ë¶€
#         "items": [                              # ê° STT segmentì— ëŒ€í•œ rewrite ê²°ê³¼
#             {
#                 "raw": str,                     # ì›ë³¸ STT í…ìŠ¤íŠ¸
#                 "rewritten": str,               # ì˜ë¯¸ ë³´ì¡´í•œ ì •ì œ í…ìŠ¤íŠ¸
#                 "ok": bool | None,              # ì˜ë¯¸ ìœ ì§€ í‰ê°€ ê²°ê³¼ (None â†’ í‰ê°€ ì „)
#                 "judge_notes": List[str]        # íŒë‹¨ ê·¼ê±° (ë¬¸ì¥ ëˆ„ë½ ë“±)
#             }
#         ],
#         "final": [                              # ok=Trueì¸ í•­ëª©ë§Œ ëˆ„ì  (í‰ê°€/ë¦¬í¬íŠ¸ ëŒ€ìƒ)
#             {
#                 "raw": str,
#                 "rewritten": str,
#                 "timestamp": str                # (ì˜µì…˜) í•´ë‹¹ ë°œí™” ì‹œì 
#             }
#         ]
#     },

#     "decision_log": [                           # ëª¨ë“  ì²˜ë¦¬ ì´ë ¥
#         {
#             "step": str,                        # ì˜ˆ: "rewrite_agent", "pdf_node"
#             "result": str,                      # ì˜ˆ: "done", "ok=False"
#             "time": str,                        # ISO timestamp
#             "details": dict                     # ë‹¨ê³„ë³„ ë©”íƒ€ë°ì´í„°
#         }
#     ],

#     "evaluation": {
#         "done": bool,                           # í‰ê°€ ì™„ë£Œ ì—¬ë¶€
#         "results": dict | None,                 # ê° ì—­ëŸ‰ í‚¤ì›Œë“œë³„ ì ìˆ˜
#         "ok": bool | None,                      # í‰ê°€ ìŠ¤ì½”ì–´ í˜•ì‹/ë²”ìœ„ ìœ íš¨ ì—¬ë¶€
#         "judge_notes": List[str]                # ë¬¸ì œ ë°œìƒ ì‹œ ê·¼ê±°
#     },

#     "report": {
#         "pdf": {
#             "generated": bool,
#             "path": str | None                  # ìƒì„±ëœ PDF íŒŒì¼ ê²½ë¡œ
#         },
#         "excel": {
#             "generated": bool,
#             "path": str | None                  # ìƒì„±ëœ Excel íŒŒì¼ ê²½ë¡œ (í™•ì¥ ì˜ˆì •)
#         }
#     },

#     # (ì˜µì…˜) ìŒì„± íŒŒì¼ ê²½ë¡œ (WebSocket ì¢…ë£Œ ì‹œì ì—ì„œ ì¼ì‹œì ìœ¼ë¡œ ì‚¬ìš©ë¨)
#     "audio_path": str | None
# }

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ë…¸ë“œ ë° ì—ì´ì „íŠ¸ ì •ì˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

#  Available Nodes & Agents
# Nodes  : stt_node, append_node, pdf_node, excel_node
# Agents : rewrite_agent, judge_rewrite, evaluation_agent, judge_evaluation

def stt_node(state: dict) -> dict:
    audio_path = state.get("audio_path")
    interviewee_id = state["interviewee_id"]
    raw = transcribe_audio_file(audio_path)
    ts = datetime.now().isoformat()
    state.setdefault("stt", {"done": False, "segments": []})
    state["stt"]["segments"].append({"raw": raw, "timestamp": ts})
    state["decision_log"].append({
        "step": "stt_node",
        "result": "success",
        "time": ts,
        "details": {"segment": raw[:30]}
    })
    return state

async def rewrite_agent(state: dict) -> dict:
    """
    1) ê°€ì¥ ìµœê·¼ STT segment ì›ë¬¸ì„ **ì˜ë¯¸ ë³€í™”ë‚˜ ìš”ì•½ ì—†ì´** ì •ì œ(rewrite)
       - ë¬¸ë²• ì˜¤ë¥˜, ì˜¤íƒˆì, ê³µë°±ë§Œ ìˆ˜ì •
    2) state['rewrite']['items']ì— raw, rewritten, ok=None, judge_notes=[] ì¶”ê°€
    """
    raw = state["stt"]["segments"][-1]["raw"]
    rewritten, _ = await rewrite_answer(raw)
    item = {"raw": raw, "rewritten": rewritten, "ok": None, "judge_notes": []}
    state.setdefault("rewrite", {"done": False, "items": []})
    state["rewrite"]["items"].append(item)
    ts = datetime.now().isoformat()
    state["decision_log"].append({
        "step": "rewrite_agent",
        "result": "processing",
        "time": ts,
        "details": {"raw_preview": raw[:30]}
    })
    return state

# rewrite judge agent
async def judge_rewrite(state: dict) -> dict:
    """
    1) raw vs rewritten ë¹„êµí•˜ì—¬ ok/false ê²°ì •
    2) ë§ˆì§€ë§‰ rewrite itemì— ok ë° judge_notes ì—…ë°ì´íŠ¸
    """
    import json
    import openai
    item = state["rewrite"]["items"][-1]
    raw = item["raw"]
    rewritten = item["rewritten"]
    notes = []
    ok = True
    ratio = len(rewritten) / len(raw) if raw else 1.0
    if ratio < 0.8 or ratio > 1.2:
        ok = False
        notes.append(f"Length ratio {ratio:.2f} out of bounds (0.8~1.2)")
    if ok:
        prompt = f"""
ì‹œìŠ¤í…œ: ë‹¹ì‹ ì€ í…ìŠ¤íŠ¸ ë¦¬ë¼ì´íŒ… í‰ê°€ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì›ë³¸: \"{raw}\"
ë¦¬ë¼ì´íŒ…: \"{rewritten}\"
1) ì˜ë¯¸ ë³´ì¡´
2) ê³¼ì‰ ì¶•ì•½/í™•ì¥
3) ì˜¤íƒˆì/ë¬¸ë§¥ ì˜¤ë¥˜
ìœ„ ê¸°ì¤€ì— ë”°ë¼ JSON í˜•ì‹ìœ¼ë¡œ ok(bool)ì™€ notes(list)ë¥¼ ë°˜í™˜í•˜ì„¸ìš”.
"""
        resp = openai.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": prompt}],
            temperature=0
        )
        try:
            data = json.loads(resp.choices[0].message.content)
            ok = data.get("ok", ok)
            notes.extend(data.get("notes", []))
        except json.JSONDecodeError:
            notes.append("GPT validation parse error")
    item["ok"] = ok
    item["judge_notes"] = notes
    ts = datetime.now().isoformat()
    state["decision_log"].append({
        "step": "judge_rewrite",
        "result": "pass" if ok else "fail",
        "time": ts,
        "details": {"notes": notes}
    })
    return state

# rewrite ê²°ê³¼ë¬¼ ì¶”ê°€ node
def append_node(state: dict) -> dict:
    state.setdefault("rewrite", {}).setdefault("items", [])
    state["rewrite"].setdefault("final", [])
    ts = datetime.now().isoformat()
    if not state["rewrite"]["items"]:
        state["decision_log"].append({"step": "append_node", "result": "skipped (no items)", "time": ts, "details": {}})
        return state
    latest_item = state["rewrite"]["items"][-1]
    if latest_item.get("ok") is True:
        state["rewrite"]["final"].append(latest_item)
        state["decision_log"].append({"step": "append_node", "result": "appended", "time": ts, "details": {"rewritten_preview": latest_item["rewritten"][:30]}})
    else:
        state["decision_log"].append({"step": "append_node", "result": "skipped (not ok)", "time": ts, "details": {}})
    return state


# í‰ê°€ agent
async def evaluation_agent(state: dict) -> dict:
    """
    í‰ê°€ ê²°ê³¼ ìƒì„±
    """
    import json
    import openai
    from datetime import datetime
    import re

    # í‰ê°€í•  í…ìŠ¤íŠ¸ ì¤€ë¹„
    rewritten_items = state.get("rewrite", {}).get("final", [])
    if not rewritten_items:
        state.setdefault("evaluation", {})["done"] = False
        state.setdefault("evaluation", {})["error"] = "í‰ê°€í•  í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤."
        return state

    # í‰ê°€í•  í…ìŠ¤íŠ¸ë¥¼ í•˜ë‚˜ì˜ ë¬¸ìì—´ë¡œ ê²°í•©
    text_to_evaluate = "\n".join([item.get("rewritten", "") for item in rewritten_items])
    
    # í‰ê°€ í”„ë¡¬í”„íŠ¸ ìƒì„±
    prompt = f"""
ì‹œìŠ¤í…œ: ë‹¹ì‹ ì€ ë©´ì ‘ í‰ê°€ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ë‹¤ìŒ ë©´ì ‘ ë‹µë³€ì„ í‰ê°€í•´ì£¼ì„¸ìš”:

{text_to_evaluate}

ë‹¤ìŒ ê¸°ì¤€ìœ¼ë¡œ í‰ê°€í•´ì£¼ì„¸ìš”:
1. ì „ë¬¸ì„± (0-5ì )
2. ë…¼ë¦¬ì„± (0-5ì )
3. ì˜ì‚¬ì†Œí†µëŠ¥ë ¥ (0-5ì )
4. ë¬¸ì œí•´ê²°ëŠ¥ë ¥ (0-5ì )
5. ì ê·¹ì„± (0-5ì )

JSON í˜•ì‹ìœ¼ë¡œë§Œ ë°˜í™˜í•´ì£¼ì„¸ìš” (ë§ˆí¬ë‹¤ìš´ì´ë‚˜ ë‹¤ë¥¸ í˜•ì‹ ì—†ì´):
{{
    "ì „ë¬¸ì„±": {{"score": ì ìˆ˜, "reason": "í‰ê°€ ì´ìœ "}},
    "ë…¼ë¦¬ì„±": {{"score": ì ìˆ˜, "reason": "í‰ê°€ ì´ìœ "}},
    "ì˜ì‚¬ì†Œí†µëŠ¥ë ¥": {{"score": ì ìˆ˜, "reason": "í‰ê°€ ì´ìœ "}},
    "ë¬¸ì œí•´ê²°ëŠ¥ë ¥": {{"score": ì ìˆ˜, "reason": "í‰ê°€ ì´ìœ "}},
    "ì ê·¹ì„±": {{"score": ì ìˆ˜, "reason": "í‰ê°€ ì´ìœ "}}
}}
"""
    try:
        response = openai.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": prompt}],
            temperature=0
        )
        result_text = response.choices[0].message.content.strip()
        
        # ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡ ì œê±°
        result_text = re.sub(r'```json\s*|\s*```', '', result_text)
        
        # JSON íŒŒì‹± ì‹œë„
        try:
            results = json.loads(result_text)
            # ì ìˆ˜ ë²”ìœ„ ê²€ì¦
            for key, value in results.items():
                score = value.get("score", 0)
                if not isinstance(score, (int, float)) or score < 0 or score > 5:
                    value["score"] = max(0, min(5, float(score)))
                if not value.get("reason"):
                    value["reason"] = "í‰ê°€ ì´ìœ  ì—†ìŒ"
            
            state.setdefault("evaluation", {})["results"] = results
            state["evaluation"]["done"] = True
            ts = datetime.now().isoformat()
            state.setdefault("decision_log", []).append({
                "step": "evaluation_agent",
                "result": "done",
                "time": ts,
                "details": {}
            })
        except json.JSONDecodeError as e:
            print(f"âš ï¸ JSON íŒŒì‹± ì˜¤ë¥˜: {str(e)}")
            print(f"ì›ë³¸ í…ìŠ¤íŠ¸: {result_text}")
            # ê¸°ë³¸ í‰ê°€ ê²°ê³¼ ìƒì„±
            default_results = {
                "ì „ë¬¸ì„±": {"score": 3, "reason": "ê¸°ë³¸ ì ìˆ˜ ë¶€ì—¬"},
                "ë…¼ë¦¬ì„±": {"score": 3, "reason": "ê¸°ë³¸ ì ìˆ˜ ë¶€ì—¬"},
                "ì˜ì‚¬ì†Œí†µëŠ¥ë ¥": {"score": 3, "reason": "ê¸°ë³¸ ì ìˆ˜ ë¶€ì—¬"},
                "ë¬¸ì œí•´ê²°ëŠ¥ë ¥": {"score": 3, "reason": "ê¸°ë³¸ ì ìˆ˜ ë¶€ì—¬"},
                "ì ê·¹ì„±": {"score": 3, "reason": "ê¸°ë³¸ ì ìˆ˜ ë¶€ì—¬"}
            }
            state.setdefault("evaluation", {})["results"] = default_results
            state["evaluation"]["done"] = True
            state["evaluation"]["error"] = f"JSON íŒŒì‹± ì˜¤ë¥˜: {str(e)}"
            ts = datetime.now().isoformat()
            state.setdefault("decision_log", []).append({
                "step": "evaluation_agent",
                "result": "error",
                "time": ts,
                "details": {"error": str(e)}
            })
    except Exception as e:
        state.setdefault("evaluation", {})["done"] = False
        state["evaluation"]["error"] = str(e)
        ts = datetime.now().isoformat()
        state.setdefault("decision_log", []).append({
            "step": "evaluation_agent",
            "result": "error",
            "time": ts,
            "details": {"error": str(e)}
        })
    return state

# í‰ê°€ judge agent
async def judge_evaluation(state: dict) -> dict:
    """
    í‰ê°€ ê²°ê³¼ ê²€ì¦
    """
    import json
    import openai
    from jsonschema import validate, ValidationError
    from datetime import datetime

    results = state.get("evaluation", {}).get("results", {})
    if not results:
        state.setdefault("evaluation", {})["ok"] = False
        state.setdefault("evaluation", {})["judge_notes"] = ["í‰ê°€ ê²°ê³¼ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤."]
        ts = datetime.now().isoformat()
        state.setdefault("decision_log", []).append({
            "step": "judge_evaluation",
            "result": "fail",
            "time": ts,
            "details": {"notes": ["í‰ê°€ ê²°ê³¼ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤."]}
        })
        return state

    notes, ok = [], True
    schema = {
        "type": "object",
        "properties": {
            "ì „ë¬¸ì„±": {"type": "object", "required": ["score", "reason"]},
            "ë…¼ë¦¬ì„±": {"type": "object", "required": ["score", "reason"]},
            "ì˜ì‚¬ì†Œí†µëŠ¥ë ¥": {"type": "object", "required": ["score", "reason"]},
            "ë¬¸ì œí•´ê²°ëŠ¥ë ¥": {"type": "object", "required": ["score", "reason"]},
            "ì ê·¹ì„±": {"type": "object", "required": ["score", "reason"]}
        },
        "required": ["ì „ë¬¸ì„±", "ë…¼ë¦¬ì„±", "ì˜ì‚¬ì†Œí†µëŠ¥ë ¥", "ë¬¸ì œí•´ê²°ëŠ¥ë ¥", "ì ê·¹ì„±"]
    }

    try:
        validate(results, schema)
    except ValidationError as e:
        ok = False
        notes.append(f"ìŠ¤í‚¤ë§ˆ ì˜¤ë¥˜: {e.message}")

    total = 0
    for comp, detail in results.items():
        score = detail.get("score", 0)
        if not isinstance(score, (int, float)) or score < 0 or score > 5:
            ok = False
            notes.append(f"{comp} ì ìˆ˜ê°€ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {score}")
        total += score

    if total < 0 or total > 25:
        ok = False
        notes.append(f"ì´ì ì´ ë²”ìœ„ë¥¼ ë²—ì–´ë‚¬ìŠµë‹ˆë‹¤: {total}")

    if ok:
        prompt = f"""
ì‹œìŠ¤í…œ: ë‹¹ì‹ ì€ ë©´ì ‘ í‰ê°€ ê²€ì¦ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
í‰ê°€ ê²°ê³¼:
{json.dumps(results, ensure_ascii=False, indent=2)}

ì´ í‰ê°€ê°€ ì ì ˆí•œì§€ ê²€ì¦í•´ì£¼ì„¸ìš”.
JSON í˜•ì‹ìœ¼ë¡œë§Œ ë°˜í™˜í•´ì£¼ì„¸ìš” (ë§ˆí¬ë‹¤ìš´ì´ë‚˜ ë‹¤ë¥¸ í˜•ì‹ ì—†ì´):
{{
    "ok": true/false,
    "notes": ["ê²€ì¦ ë©”ì‹œì§€"]
}}
"""
        try:
            response = openai.chat.completions.create(
                model="gpt-4o-mini",
                messages=[{"role": "user", "content": prompt}],
                temperature=0
            )
            judge_result = json.loads(response.choices[0].message.content.strip())
            ok = judge_result.get("ok", False)
            notes.extend(judge_result.get("notes", []))
        except Exception as e:
            ok = False
            notes.append(f"ê²€ì¦ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

    state.setdefault("evaluation", {})["ok"] = ok
    state["evaluation"]["judge_notes"] = notes
    ts = datetime.now().isoformat()
    state.setdefault("decision_log", []).append({
        "step": "judge_evaluation",
        "result": "ok" if ok else "fail",
        "time": ts,
        "details": {"notes": notes}
    })
    return state

# ìµœì¢… ë ˆí¬íŠ¸ pdf node
async def pdf_node(state: dict) -> dict:
    questions = state.get("questions", [])
    answers = [item["rewritten"] for item in state.get("rewrite", {}).get("final", [])]
    
    # 1) í‰ê°€ ê²°ê³¼ keyword_results ë³€í™˜
    evaluation_results = state.get("evaluation", {}).get("results", {})
    if not evaluation_results:
        state.setdefault("report", {}).setdefault("pdf", {})["generated"] = False
        state["report"]["pdf"]["error"] = "í‰ê°€ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤."
        return state

    keyword_results = {
        kw: {
            "score": detail.get("score", 0),
            "reasons": detail.get("reason", "í‰ê°€ ì´ìœ  ì—†ìŒ")
        }
        for kw, detail in evaluation_results.items()
    }

    # 2) QA ë¸”ë¡ í…ìŠ¤íŠ¸ ìƒì„± (GPT í˜¸ì¶œ í¬í•¨)
    qa_blocks_text = await reconstruct_qa_blocks(questions, answers)
    
    cid = state.get("interviewee_id")
    ts = datetime.now().strftime('%Y%m%d%H%M%S')
    out_dir = './results'
    os.makedirs(out_dir, exist_ok=True)
    chart_path = os.path.join(out_dir, f"{cid}_chart_{ts}.png")
    pdf_path = os.path.join(out_dir, f"{cid}_report_{ts}.pdf")
    
    # 3) ì°¨íŠ¸ ìƒì„± ë° PDF ìƒì„±
    try:
        create_radar_chart(keyword_results, chart_path)
        generate_pdf(
            keyword_results=keyword_results,
            chart_path=chart_path,
            output_path=pdf_path,
            interviewee_id=cid,
            qa_blocks_text=qa_blocks_text,
            total_score=sum(item.get("score", 0) for item in keyword_results.values())
        )
        state.setdefault("report", {}).setdefault("pdf", {})["generated"] = True
        state["report"]["pdf"]["path"] = pdf_path
        ts2 = datetime.now().isoformat()
        state.setdefault("decision_log", []).append({
            "step": "pdf_node", 
            "result": "generated", 
            "time": ts2, 
            "details": {"path": pdf_path}
        })
    except Exception as e:
        state.setdefault("report", {}).setdefault("pdf", {})["generated"] = False
        state["report"]["pdf"]["error"] = str(e)
        ts2 = datetime.now().isoformat()
        state.setdefault("decision_log", []).append({
            "step": "pdf_node", 
            "result": "error", 
            "time": ts2, 
            "details": {"error": str(e)}
        })
    return state

#  ì—‘ì…€ nodeë„ ë¹„ë™ê¸°ë¡œ ë³€ê²½
async def excel_node(state: dict) -> dict:
    state.setdefault("report", {})["excel"] = {"generated": False, "path": None}
    return state



# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Flush ìœ í‹¸ë¦¬í‹°: í‰ê°€ ì „ STT/Rewrite ì”ì—¬ ì²˜ë¦¬ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
async def flush_pending_segments(state: dict) -> dict:
    """
    ë§ˆì§€ë§‰ STT í•­ëª©ì´ ì•„ì§ rewriteë˜ì§€ ì•Šì•˜ë‹¤ë©´ rewrite ì²˜ë¦¬ â†’ í‰ê°€ ì „ì— ë°˜ë“œì‹œ ì‹¤í–‰í•´ì•¼ í•¨.
    """
    segments = state.get("stt", {}).get("segments", [])
    items = state.get("rewrite", {}).get("items", [])
    if len(segments) > len(items):
        state = await rewrite_agent(state)
        state = await judge_rewrite(state)
        state = append_node(state)
    if state.get("rewrite", {}).get("items"):
        last_item = state["rewrite"]["items"][-1]
        if last_item.get("ok") is True:
            state["rewrite"]["done"] = True
    return state


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# LangGraph íŒŒì´í”„ë¼ì¸ ì •ì˜ (interview_flow / final_report_flow)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

"""
ğŸ™ï¸ í•œ ë°œí™” ì¢…ë£Œ ì‹œ í˜¸ì¶œë˜ëŠ” ì²˜ë¦¬ íë¦„ì…ë‹ˆë‹¤.

    [ì‹¤í–‰ ìˆœì„œ]

    1. STT Node
       - state['audio_path']ì— í•´ë‹¹í•˜ëŠ” ìŒì„±ì„ Whisperë¡œ ì „ì‚¬
       - ê²°ê³¼ëŠ” state['stt']['segments']ì— ëˆ„ì  ì €ì¥

    2. Rewrite Agent
       - ê°€ì¥ ìµœê·¼ STT segmentë¥¼ ë¬¸ë²•ì ìœ¼ë¡œ ì •ì œ (ì˜ë¯¸ ë³€í™” ì—†ì´)
       - ì •ì œ ê²°ê³¼ëŠ” state['rewrite']['items']ì— ì¶”ê°€ë¨

    3. Judge Rewrite Agent
       - ì •ì œëœ ë¬¸ì¥ì´ ì›ë¬¸ ì˜ë¯¸ë¥¼ ìœ ì§€í•˜ëŠ”ì§€ í‰ê°€
       - í‰ê°€ ê²°ê³¼ (ok ì—¬ë¶€ ë° ê·¼ê±°)ëŠ” state['rewrite']['items'][-1]ì— ê¸°ë¡ë¨

    4. (ì„ íƒì ) Retry Logic
       - ë§Œì•½ ok=Falseì¼ ê²½ìš°, Rewrite â†’ Judgeë¥¼ ìµœëŒ€ NíšŒ ì¬ì‹¤í–‰

    5. Append Node
       - ok=Trueì¸ segmentë§Œ state['rewrite']['final']ì— ìµœì¢… ëˆ„ì 

    [êµ¬í˜„ ê°€ì´ë“œ]
    - ê° ë‹¨ê³„ëŠ” ì•„ë˜ ë°©ì‹ìœ¼ë¡œ í˜¸ì¶œí•©ë‹ˆë‹¤:
        state = graph.run_node("stt_node", state)
        state = await graph.run_agent("rewrite_agent", state)
        ...
    """

# interview_flow_executor
interview_builder = StateGraph(dict)
interview_builder.add_node("stt_node", stt_node)
interview_builder.add_node("rewrite_agent", rewrite_agent)
interview_builder.add_node("judge_rewrite", judge_rewrite)
interview_builder.add_node("append_node", append_node)
interview_builder.set_entry_point("stt_node")
interview_builder.add_edge("stt_node", "rewrite_agent")
interview_builder.add_edge("rewrite_agent", "judge_rewrite")
interview_builder.add_edge("judge_rewrite", "append_node")
interview_flow_executor = interview_builder.compile()





# final_report_flow_executor
"""
    ğŸ“„ ë©´ì ‘ ì¢…ë£Œ ì‹œ ì‹¤í–‰ë˜ëŠ” ì „ì²´ í‰ê°€ ë° ë³´ê³ ì„œ ìƒì„± íë¦„ì…ë‹ˆë‹¤.

    [ì‹¤í–‰ ìˆœì„œ]

    0. flush_pending_segments
       - ì•„ì§ appendë˜ì§€ ì•Šì€ rewrite í›„ë³´ê°€ ìˆë‹¤ë©´ ì²˜ë¦¬
       - state['rewrite']['final'] ìµœì‹  ìƒíƒœë¥¼ ë³´ì¥

    1. Evaluation Agent
       - state['rewrite']['final'] ê¸°ì¤€ìœ¼ë¡œ GPT í‰ê°€ ìˆ˜í–‰
       - ê²°ê³¼ëŠ” state['evaluation']['results']ì— ì €ì¥

    2. Judge Evaluation Agent
       - í‰ê°€ ì ìˆ˜ í˜•ì‹ ë° ë²”ìœ„ë¥¼ ê²€ì¦
       - ë¬¸ì œê°€ ìˆë‹¤ë©´ state['evaluation']['ok'] = False
       - í‰ê°€ ì‚¬ìœ ëŠ” state['evaluation']['judge_notes']ì— ê¸°ë¡

    3. (ì„ íƒì ) Retry Logic
       - ok=Falseì¼ ê²½ìš°, Evaluation â†’ Judgeë¥¼ ìµœëŒ€ NíšŒ ë°˜ë³µ

    4. PDF Node
       - Radar Chart + í‰ê°€ ì‚¬ìœ ë¥¼ í¬í•¨í•œ PDF ë¦¬í¬íŠ¸ ìƒì„±
       - ê²°ê³¼ ê²½ë¡œëŠ” state['report']['pdf']['path']ì— ì €ì¥ë¨

    5. Excel Node (ë¯¸êµ¬í˜„)
       - ì§ˆë¬¸, ë‹µë³€, ì ìˆ˜, í‰ê°€ ì´ìœ ë¥¼ Excelë¡œ ì €ì¥ (í–¥í›„ í™•ì¥)

    [êµ¬í˜„ ê°€ì´ë“œ]
    - ê° ë‹¨ê³„ëŠ” ì•„ë˜ ë°©ì‹ìœ¼ë¡œ í˜¸ì¶œí•©ë‹ˆë‹¤:
        state = await flush_pending_segments(state)
        state = await graph.run_agent("evaluation_agent", state)
        ...
    """
final_builder = StateGraph(dict)
final_builder.add_node("flush_node", flush_pending_segments)
final_builder.add_node("evaluation_agent", evaluation_agent)
final_builder.add_node("judge_evaluation", judge_evaluation)
final_builder.add_node("pdf_node", pdf_node)
final_builder.add_node("excel_node", excel_node)
final_builder.set_entry_point("flush_node")
final_builder.add_edge("flush_node", "evaluation_agent")
final_builder.add_edge("evaluation_agent", "judge_evaluation")
final_builder.add_edge("judge_evaluation", "pdf_node")
final_builder.add_edge("pdf_node", "excel_node")
final_report_flow_executor = final_builder.compile()
# app/services/pipeline/graph_pipeline.py

# from langgraph.graph import StateGraph
# from datetime import datetime
# import os
# import asyncio

# # ì„œë¹„ìŠ¤ í•¨ìˆ˜ ì„í¬íŠ¸
# from app.services.interview.stt_service import transcribe_audio_file
# from app.services.interview.rewrite_service import rewrite_answer
# from app.services.interview.evaluation_service import evaluate_keywords_from_full_answer
# from app.services.interview.report_service import create_radar_chart, generate_pdf
# from app.services.interview.qa_reconstructor import reconstruct_qa_blocks

# # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ìƒíƒœ(state) êµ¬ì¡° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# # ê° ì—ì´ì „íŠ¸/ë…¸ë“œ í˜¸ì¶œ ì‹œ ì¸ìë¡œ ì „ë‹¬ë©ë‹ˆë‹¤.
# # ì§€ì›ì ë‹¨ìœ„ë¡œ ë…ë¦½ ì‹¤í–‰ ê°€ëŠ¥í•˜ë„ë¡ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤.
# #
# # state = {
# #     "interviewee_id": str,                      # ì§€ì›ì ID
# #     "interview_ended": bool,                    # ë©´ì ‘ ì¢…ë£Œ ì—¬ë¶€
# #     "questions": List[str],                     # StartInterview ì‹œ ì£¼ì…

# #     "stt": {
# #         "segments": [                           # ëˆ„ì ëœ STT ê²°ê³¼ ëª©ë¡
# #             {
# #                 "raw": str,                     # ì›ë¬¸ ì „ì‚¬ í…ìŠ¤íŠ¸
# #                 "timestamp": str                # ë°œí™” ì‹œì  (ì„ íƒì‚¬í•­: "00:01:23")
# #               }
# #         ]
# #     },

# #     "rewrite": {
# #         "done": bool,                           # ì „ì²´ ë¦¬ë¼ì´íŒ… ì¢…ë£Œ ì—¬ë¶€
# #         "items": [                              # ê° STT segmentì— ëŒ€í•œ rewrite ê²°ê³¼
# #             {
# #                 "raw": str,                     # ì›ë³¸ STT í…ìŠ¤íŠ¸
# #                 "rewritten": str,               # ì˜ë¯¸ ë³´ì¡´í•œ ì •ì œ í…ìŠ¤íŠ¸
# #                 "ok": bool | None,              # ì˜ë¯¸ ìœ ì§€ í‰ê°€ ê²°ê³¼ (None â†’ í‰ê°€ ì „)
# #                 "judge_notes": List[str]        # íŒë‹¨ ê·¼ê±° (ë¬¸ì¥ ëˆ„ë½ ë“±)
# #             }
# #         ],
# #         "final": [                              # ok=Trueì¸ í•­ëª©ë§Œ ëˆ„ì  (í‰ê°€/ë¦¬í¬íŠ¸ ëŒ€ìƒ)
# #             {
# #                 "raw": str,
# #                 "rewritten": str,
# #                 "timestamp": str                # (ì˜µì…˜) í•´ë‹¹ ë°œí™” ì‹œì 
# #             }
# #         ]
# #     },

# #     "decision_log": [                           # ëª¨ë“  ì²˜ë¦¬ ì´ë ¥
# #         {
# #             "step": str,                        # ì˜ˆ: "rewrite_agent", "pdf_node"
# #             "result": str,                      # ì˜ˆ: "done", "ok=False"
# #             "time": str,                        # ISO timestamp
# #             "details": dict                     # ë‹¨ê³„ë³„ ë©”íƒ€ë°ì´í„°
# #         }
# #     ],

# #     "evaluation": {
# #         "done": bool,                           # í‰ê°€ ì™„ë£Œ ì—¬ë¶€
# #         "results": dict | None,                 # ê° ì—­ëŸ‰ í‚¤ì›Œë“œë³„ ì ìˆ˜
# #         "ok": bool | None,                      # í‰ê°€ ìŠ¤ì½”ì–´ í˜•ì‹/ë²”ìœ„ ìœ íš¨ ì—¬ë¶€
# #         "judge_notes": List[str]                # ë¬¸ì œ ë°œìƒ ì‹œ ê·¼ê±°
# #     },

# #     "report": {
# #         "pdf": {
# #             "generated": bool,
# #             "path": str | None                  # ìƒì„±ëœ PDF íŒŒì¼ ê²½ë¡œ
# #         },
# #         "excel": {
# #             "generated": bool,
# #             "path": str | None                  # ìƒì„±ëœ Excel íŒŒì¼ ê²½ë¡œ (í™•ì¥ ì˜ˆì •)
# #         }
# #     },

# #     # (ì˜µì…˜) ìŒì„± íŒŒì¼ ê²½ë¡œ (WebSocket ì¢…ë£Œ ì‹œì ì—ì„œ ì¼ì‹œì ìœ¼ë¡œ ì‚¬ìš©ë¨)
# #     "audio_path": str | None
# # }

# # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ë…¸ë“œ ë° ì—ì´ì „íŠ¸ ì •ì˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# #  Available Nodes & Agents
# # Nodes  : stt_node, append_node, pdf_node, excel_node
# # Agents : rewrite_agent, judge_rewrite, evaluation_agent, judge_evaluation

# def stt_node(state: dict) -> dict:
#     audio_path = state.get("audio_path")
#     interviewee_id = state["interviewee_id"]
#     raw = transcribe_audio_file(audio_path)
#     ts = datetime.now().isoformat()
#     state.setdefault("stt", {"done": False, "segments": []})
#     state["stt"]["segments"].append({"raw": raw, "timestamp": ts})
#     state["decision_log"].append({
#         "step": "stt_node",
#         "result": "success",
#         "time": ts,
#         "details": {"segment": raw[:30]}
#     })
#     return state

# async def rewrite_agent(state: dict) -> dict:
#     """
#     1) ê°€ì¥ ìµœê·¼ STT segment ì›ë¬¸ì„ **ì˜ë¯¸ ë³€í™”ë‚˜ ìš”ì•½ ì—†ì´** ì •ì œ(rewrite)
#        - ë¬¸ë²• ì˜¤ë¥˜, ì˜¤íƒˆì, ê³µë°±ë§Œ ìˆ˜ì •
#     2) state['rewrite']['items']ì— raw, rewritten, ok=None, judge_notes=[] ì¶”ê°€
#     """
#     raw = state["stt"]["segments"][-1]["raw"]
#     rewritten, _ = await rewrite_answer(raw)
#     item = {"raw": raw, "rewritten": rewritten, "ok": None, "judge_notes": []}
#     state.setdefault("rewrite", {"done": False, "items": []})
#     state["rewrite"]["items"].append(item)
#     ts = datetime.now().isoformat()
#     state["decision_log"].append({
#         "step": "rewrite_agent",
#         "result": "processing",
#         "time": ts,
#         "details": {"raw_preview": raw[:30]}
#     })
#     return state

# # rewrite judge agent
# async def judge_rewrite(state: dict) -> dict:
#     """
#     1) raw vs rewritten ë¹„êµí•˜ì—¬ ok/false ê²°ì •
#     2) ë§ˆì§€ë§‰ rewrite itemì— ok ë° judge_notes ì—…ë°ì´íŠ¸
#     """
#     import json
#     import openai
#     item = state["rewrite"]["items"][-1]
#     raw = item["raw"]
#     rewritten = item["rewritten"]
#     notes = []
#     ok = True
#     ratio = len(rewritten) / len(raw) if raw else 1.0
#     if ratio < 0.8 or ratio > 1.2:
#         ok = False
#         notes.append(f"Length ratio {ratio:.2f} out of bounds (0.8~1.2)")
#     if ok:
#         prompt = f"""
# ì‹œìŠ¤í…œ: ë‹¹ì‹ ì€ í…ìŠ¤íŠ¸ ë¦¬ë¼ì´íŒ… í‰ê°€ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
# ì›ë³¸: \"{raw}\"
# ë¦¬ë¼ì´íŒ…: \"{rewritten}\"
# 1) ì˜ë¯¸ ë³´ì¡´
# 2) ê³¼ì‰ ì¶•ì•½/í™•ì¥
# 3) ì˜¤íƒˆì/ë¬¸ë§¥ ì˜¤ë¥˜
# ìœ„ ê¸°ì¤€ì— ë”°ë¼ JSON í˜•ì‹ìœ¼ë¡œ ok(bool)ì™€ notes(list)ë¥¼ ë°˜í™˜í•˜ì„¸ìš”.
# """
#         resp = await openai.ChatCompletion.acreate(
#             model="gpt-4o-mini",
#             messages=[{"role": "user", "content": prompt}],
#             temperature=0
#         )
#         try:
#             data = json.loads(resp.choices[0].message.content)
#             ok = data.get("ok", ok)
#             notes.extend(data.get("notes", []))
#         except json.JSONDecodeError:
#             notes.append("GPT validation parse error")
#     item["ok"] = ok
#     item["judge_notes"] = notes
#     ts = datetime.now().isoformat()
#     state["decision_log"].append({
#         "step": "judge_rewrite",
#         "result": "pass" if ok else "fail",
#         "time": ts,
#         "details": {"notes": notes}
#     })
#     return state

# # rewrite ê²°ê³¼ë¬¼ ì¶”ê°€ node
# def append_node(state: dict) -> dict:
#     state.setdefault("rewrite", {}).setdefault("items", [])
#     state["rewrite"].setdefault("final", [])
#     ts = datetime.now().isoformat()
#     if not state["rewrite"]["items"]:
#         state["decision_log"].append({"step": "append_node", "result": "skipped (no items)", "time": ts, "details": {}})
#         return state
#     latest_item = state["rewrite"]["items"][-1]
#     if latest_item.get("ok") is True:
#         state["rewrite"]["final"].append(latest_item)
#         state["decision_log"].append({"step": "append_node", "result": "appended", "time": ts, "details": {"rewritten_preview": latest_item["rewritten"][:30]}})
#     else:
#         state["decision_log"].append({"step": "append_node", "result": "skipped (not ok)", "time": ts, "details": {}})
#     return state


# # í‰ê°€ agent
# async def evaluation_agent(state: dict) -> dict:
#     final_items = state.get("rewrite", {}).get("final", [])
#     all_text = "\n".join([it["rewritten"] for it in final_items])
#     results = await evaluate_keywords_from_full_answer(all_text)
#     state["evaluation"] = {"done": True, "results": results, "ok": None, "judge_notes": []}
#     ts = datetime.now().isoformat()
#     state["decision_log"].append({"step": "evaluation_agent", "result": "done", "time": ts, "details": {}})
#     return state

# # í‰ê°€ judge agent
# async def judge_evaluation(state: dict) -> dict:
#     """
#     í‰ê°€ ê²°ê³¼ ê²€ì¦
#     """
#     import json
#     import openai
#     from jsonschema import validate, ValidationError
#     results = state.get("evaluation", {}).get("results", {})
#     notes, ok = [], True
#     schema = {"type": "object", "additionalProperties": {"type": "object"}}
#     try:
#         validate(results, schema)
#     except ValidationError as e:
#         ok = False
#         notes.append(f"Schema error: {e.message}")
#     total = 0
#     for comp, detail in results.items():
#         scores = detail.get("scores", {})
#         comp_sum = sum(s.get("score", 0) for s in scores.values())
#         if comp_sum < 3 or comp_sum > 15:
#             ok = False
#             notes.append(f"{comp} sum out of range: {comp_sum}")
#         total += comp_sum
#     if total < 0 or total > 150:
#         ok = False
#         notes.append(f"Total score out of 0~150: {total}")
#     if ok:
#         prompt = f"""
# ì‹œìŠ¤í…œ: ë‹¹ì‹ ì€ ë©´ì ‘ í‰ê°€ ê²€ì¦ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
# ì‚¬ìš©ì í‰ê°€ ê²°ê³¼ JSON:
# {json.dumps(results)}
# ê¸°ì¤€ì— ë§ëŠ”ì§€ JSON í˜•íƒœë¡œ { '{"ok":bool, "notes": [str]}' } ë°˜í™˜í•˜ì„¸ìš”.
# """
#         resp = await openai.ChatCompletion.acreate(
#             model="gpt-4o-mini",
#             messages=[{"role": "user", "content": prompt}],
#             temperature=0
#         )
#         try:
#             data = json.loads(resp.choices[0].message.content)
#             ok = data.get("ok", ok)
#             notes.extend(data.get("notes", []))
#         except json.JSONDecodeError:
#             ok = False
#             notes.append("GPT eval parse error")
#     state["evaluation"]["ok"] = ok
#     state["evaluation"]["judge_notes"] = notes
#     ts = datetime.now().isoformat()
#     state["decision_log"].append({"step": "judge_evaluation", "result": "pass" if ok else "fail", "time": ts, "details": {"notes": notes}})
#     return state

# # ìµœì¢… ë ˆí¬íŠ¸ pdf node
# def pdf_node(state: dict) -> dict:
#     questions = state.get("questions", [])
#     answers = [item["rewritten"] for item in state.get("rewrite", {}).get("final", [])]
    
#     # 1) í‰ê°€ ê²°ê³¼ keyword_results ë³€í™˜
#     keyword_results = {
#         kw: {
#             "score": sum(v["score"] for v in det["scores"].values()),
#             "reasons": "\n".join(v.get("reason", "") for v in det["scores"].values())
#         }
#         for kw, det in state.get("evaluation", {}).get("results", {}).items()
#     }

#     # 2) QA ë¸”ë¡ í…ìŠ¤íŠ¸ ìƒì„± (GPT í˜¸ì¶œ í¬í•¨, ì£¼ì˜!)
#     qa_blocks_text = asyncio.run(reconstruct_qa_blocks(questions, answers))
#     cid = state.get("interviewee_id")
#     ts = datetime.now().strftime('%Y%m%d%H%M%S')
#     out_dir = './results'
#     os.makedirs(out_dir, exist_ok=True)
#     chart_path = os.path.join(out_dir, f"{cid}_chart_{ts}.png")
#     pdf_path = os.path.join(out_dir, f"{cid}_report_{ts}.pdf")
    
#     generate_pdf(
#         keyword_results=keyword_results,
#         chart_path=chart_path,
#         output_path=pdf_path,
#         interviewee_id=cid,
#         qa_blocks_text=qa_blocks_text,
#         total_score=sum(item.get("score", 0) for item in keyword_results.values())
#     )
#     state.setdefault("report", {}).setdefault("pdf", {})["generated"] = True
#     state["report"]["pdf"]["path"] = pdf_path
#     ts2 = datetime.now().isoformat()
#     state.setdefault("decision_log", []).append({"step": "pdf_node", "result": "generated", "time": ts2, "details": {"path": pdf_path}})
#     return state

# #  ì—‘ì…€ node
# def excel_node(state: dict) -> dict:
#     state.setdefault("report", {})["excel"] = {"generated": False, "path": None}
#     return state



# # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Flush ìœ í‹¸ë¦¬í‹°: í‰ê°€ ì „ STT/Rewrite ì”ì—¬ ì²˜ë¦¬ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# async def flush_pending_segments(state: dict) -> dict:
#     """
#     ë§ˆì§€ë§‰ STT í•­ëª©ì´ ì•„ì§ rewriteë˜ì§€ ì•Šì•˜ë‹¤ë©´ rewrite ì²˜ë¦¬ â†’ í‰ê°€ ì „ì— ë°˜ë“œì‹œ ì‹¤í–‰í•´ì•¼ í•¨.
#     """
#     segments = state.get("stt", {}).get("segments", [])
#     items = state.get("rewrite", {}).get("items", [])
#     if len(segments) > len(items):
#         state = await rewrite_agent(state)
#         state = await judge_rewrite(state)
#         state = append_node(state)
#     if state.get("rewrite", {}).get("items"):
#         last_item = state["rewrite"]["items"][-1]
#         if last_item.get("ok") is True:
#             state["rewrite"]["done"] = True
#     return state


# # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# # LangGraph íŒŒì´í”„ë¼ì¸ ì •ì˜ (interview_flow / final_report_flow)
# # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# """
# ğŸ™ï¸ í•œ ë°œí™” ì¢…ë£Œ ì‹œ í˜¸ì¶œë˜ëŠ” ì²˜ë¦¬ íë¦„ì…ë‹ˆë‹¤.

#     [ì‹¤í–‰ ìˆœì„œ]

#     1. STT Node
#        - state['audio_path']ì— í•´ë‹¹í•˜ëŠ” ìŒì„±ì„ Whisperë¡œ ì „ì‚¬
#        - ê²°ê³¼ëŠ” state['stt']['segments']ì— ëˆ„ì  ì €ì¥

#     2. Rewrite Agent
#        - ê°€ì¥ ìµœê·¼ STT segmentë¥¼ ë¬¸ë²•ì ìœ¼ë¡œ ì •ì œ (ì˜ë¯¸ ë³€í™” ì—†ì´)
#        - ì •ì œ ê²°ê³¼ëŠ” state['rewrite']['items']ì— ì¶”ê°€ë¨

#     3. Judge Rewrite Agent
#        - ì •ì œëœ ë¬¸ì¥ì´ ì›ë¬¸ ì˜ë¯¸ë¥¼ ìœ ì§€í•˜ëŠ”ì§€ í‰ê°€
#        - í‰ê°€ ê²°ê³¼ (ok ì—¬ë¶€ ë° ê·¼ê±°)ëŠ” state['rewrite']['items'][-1]ì— ê¸°ë¡ë¨

#     4. (ì„ íƒì ) Retry Logic
#        - ë§Œì•½ ok=Falseì¼ ê²½ìš°, Rewrite â†’ Judgeë¥¼ ìµœëŒ€ NíšŒ ì¬ì‹¤í–‰

#     5. Append Node
#        - ok=Trueì¸ segmentë§Œ state['rewrite']['final']ì— ìµœì¢… ëˆ„ì 

#     [êµ¬í˜„ ê°€ì´ë“œ]
#     - ê° ë‹¨ê³„ëŠ” ì•„ë˜ ë°©ì‹ìœ¼ë¡œ í˜¸ì¶œí•©ë‹ˆë‹¤:
#         state = graph.run_node("stt_node", state)
#         state = await graph.run_agent("rewrite_agent", state)
#         ...
#     """

# # interview_flow_executor
# # interview_flow_executor
# interview_builder = StateGraph(dict)
# interview_builder.add_node("stt_node", stt_node)
# interview_builder.add_node("rewrite_agent", rewrite_agent)
# interview_builder.add_node("judge_rewrite", judge_rewrite)
# interview_builder.add_node("append_node", append_node)
# interview_builder.set_entry_point("stt_node")
# interview_builder.add_edge("stt_node", "rewrite_agent")
# interview_builder.add_edge("rewrite_agent", "judge_rewrite")
# interview_builder.add_edge("judge_rewrite", "append_node")
# interview_flow_executor = interview_builder.compile()




# # final_report_flow_executor
# """
#     ğŸ“„ ë©´ì ‘ ì¢…ë£Œ ì‹œ ì‹¤í–‰ë˜ëŠ” ì „ì²´ í‰ê°€ ë° ë³´ê³ ì„œ ìƒì„± íë¦„ì…ë‹ˆë‹¤.

#     [ì‹¤í–‰ ìˆœì„œ]

#     0. flush_pending_segments
#        - ì•„ì§ appendë˜ì§€ ì•Šì€ rewrite í›„ë³´ê°€ ìˆë‹¤ë©´ ì²˜ë¦¬
#        - state['rewrite']['final'] ìµœì‹  ìƒíƒœë¥¼ ë³´ì¥

#     1. Evaluation Agent
#        - state['rewrite']['final'] ê¸°ì¤€ìœ¼ë¡œ GPT í‰ê°€ ìˆ˜í–‰
#        - ê²°ê³¼ëŠ” state['evaluation']['results']ì— ì €ì¥

#     2. Judge Evaluation Agent
#        - í‰ê°€ ì ìˆ˜ í˜•ì‹ ë° ë²”ìœ„ë¥¼ ê²€ì¦
#        - ë¬¸ì œê°€ ìˆë‹¤ë©´ state['evaluation']['ok'] = False
#        - í‰ê°€ ì‚¬ìœ ëŠ” state['evaluation']['judge_notes']ì— ê¸°ë¡

#     3. (ì„ íƒì ) Retry Logic
#        - ok=Falseì¼ ê²½ìš°, Evaluation â†’ Judgeë¥¼ ìµœëŒ€ NíšŒ ë°˜ë³µ

#     4. PDF Node
#        - Radar Chart + í‰ê°€ ì‚¬ìœ ë¥¼ í¬í•¨í•œ PDF ë¦¬í¬íŠ¸ ìƒì„±
#        - ê²°ê³¼ ê²½ë¡œëŠ” state['report']['pdf']['path']ì— ì €ì¥ë¨

#     5. Excel Node (ë¯¸êµ¬í˜„)
#        - ì§ˆë¬¸, ë‹µë³€, ì ìˆ˜, í‰ê°€ ì´ìœ ë¥¼ Excelë¡œ ì €ì¥ (í–¥í›„ í™•ì¥)

#     [êµ¬í˜„ ê°€ì´ë“œ]
#     - ê° ë‹¨ê³„ëŠ” ì•„ë˜ ë°©ì‹ìœ¼ë¡œ í˜¸ì¶œí•©ë‹ˆë‹¤:
#         state = await flush_pending_segments(state)
#         state = await graph.run_agent("evaluation_agent", state)
#         ...
#     """
# final_builder = StateGraph(dict)
# final_builder.add_node("flush_node", flush_pending_segments)
# final_builder.add_node("evaluation_agent", evaluation_agent)
# final_builder.add_node("judge_evaluation", judge_evaluation)
# final_builder.add_node("pdf_node", pdf_node)
# final_builder.add_node("excel_node", excel_node)
# final_builder.set_entry_point("flush_node")
# final_builder.add_edge("flush_node", "evaluation_agent")
# final_builder.add_edge("evaluation_agent", "judge_evaluation")
# final_builder.add_edge("judge_evaluation", "pdf_node")
# final_builder.add_edge("pdf_node", "excel_node")
# final_report_flow_executor = final_builder.compile()