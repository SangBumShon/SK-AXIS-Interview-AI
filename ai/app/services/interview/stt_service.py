from pydub import AudioSegment
from openai import OpenAI
import os
from dotenv import load_dotenv
from fastapi import UploadFile
import whisper
from typing import Optional
from datetime import datetime
import numpy as np


# ğŸ“¦ .env í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
dotenv_path = os.path.join(os.path.dirname(__file__), '..', '..', '.env')
load_dotenv(dotenv_path)

# ğŸ”‘ OpenAI API Key ë¡œë“œ ë° í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
openai_key = os.getenv("OPENAI_API_KEY")
if not openai_key:
    raise ValueError("âŒ OPENAI_API_KEYê°€ .envì— ì •ì˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
# OpenAI Python v1.x í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
client = OpenAI(api_key=openai_key)

# Whisper ëª¨ë¸ ì´ˆê¸°í™”
model = whisper.load_model("base")

#ğŸ§  OpenAI Whisper APIë¥¼ í†µí•œ STT ìˆ˜í–‰
def transcribe_audio_file(file_path: str) -> str:
    """
    Whisper APIë¥¼ ì‚¬ìš©í•˜ì—¬ ì£¼ì–´ì§„ ì˜¤ë””ì˜¤ íŒŒì¼ì„ í…ìŠ¤íŠ¸ë¡œ ì „ì‚¬í•¨
    """
    # ì˜¤ë””ì˜¤ ì „ì²˜ë¦¬ ë¹„í™œì„±í™” (ì›ë³¸ íŒŒì¼ ì§ì ‘ ì‚¬ìš©)
    # processed_path = preprocess_audio(file_path)
    
    with open(file_path, "rb") as f:
        transcript = client.audio.transcriptions.create(
            model="whisper-1",
            file=f,
            response_format="text",
            language="ko",
            # í”„ë¡¬í”„íŠ¸ ì¶”ê°€ë¡œ ë§¥ë½ ì œê³µ
        )
    
    # ì „ì²˜ë¦¬ëœ ì„ì‹œ íŒŒì¼ ì‚­ì œ (ì „ì²˜ë¦¬ ë¹„í™œì„±í™”ë¡œ ì£¼ì„ ì²˜ë¦¬)
    # if processed_path != file_path and os.path.exists(processed_path):
    #     os.remove(processed_path)
    
    # response_format="text" ë¥¼ ì‚¬ìš©í•˜ë©´ ë¬¸ìì—´ì´ ë°˜í™˜ë©ë‹ˆë‹¤.
    result = transcript.strip()
    
    # í›„ì²˜ë¦¬: ëª…ë°±íˆ ì˜ëª»ëœ ë³€í™˜ í•„í„°ë§
    if is_invalid_transcription(result):
        print(f"[STT í›„ì²˜ë¦¬] ì˜ëª»ëœ ë³€í™˜ ê°ì§€: {result}")
        return "ìŒì„±ì„ ëª…í™•í•˜ê²Œ ì¸ì‹í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    
    return result

def is_invalid_transcription(text: str) -> bool:
    """
    ëª…ë°±íˆ ì˜ëª»ëœ STT ê²°ê³¼ë¥¼ ê°ì§€í•©ë‹ˆë‹¤.
    """
    if not text or len(text.strip()) == 0:
        return True
    
    # ì˜ëª»ëœ ë³€í™˜ íŒ¨í„´ë“¤
    invalid_patterns = [
        "ì‹œì²­í•´ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤",
        "ì‹œì²­ í•´ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤",
        "ì˜¤ëŠ˜ë„ ì˜ìƒ ì‹œì²­ í•´ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤",
        "ë¨¹ë°©",
        "ë¹ ì´ë¹ ì´", 
        "êµ¬ë…",
        "ì˜ìƒ ì‹œì²­",
        "ì±„ë„",
        "ìœ íŠœë¸Œ"
    ]
    
    text_lower = text.lower()
    for pattern in invalid_patterns:
        if pattern in text_lower:
            return True
    
    # ë„ˆë¬´ ì§§ì€ ì˜ë¯¸ì—†ëŠ” ë‹¨ì–´ë“¤
    if len(text.strip()) < 3:
        return True
        
    return False

async def save_audio_file(interviewee_id: int, audio_file: UploadFile) -> Optional[str]:
    """
    ì—…ë¡œë“œëœ ì˜¤ë””ì˜¤ íŒŒì¼ì„ uploads ë””ë ‰í† ë¦¬ì— ì €ì¥í•©ë‹ˆë‹¤.
    
    Args:
        interviewee_id: ë©´ì ‘ì ID
        audio_file: ì—…ë¡œë“œëœ WebM ì˜¤ë””ì˜¤ íŒŒì¼
        
    Returns:
        str: ì €ì¥ëœ íŒŒì¼ ê²½ë¡œ
    """
    try:
        # uploads ë””ë ‰í† ë¦¬ ìƒì„±
        save_dir = os.path.join("uploads")
        os.makedirs(save_dir, exist_ok=True)
        
        # íŒŒì¼ëª… ìƒì„± (interviewee_id_timestamp.webm í˜•ì‹)
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"{interviewee_id}_{timestamp}.webm"
        
        # íŒŒì¼ ì €ì¥
        file_path = os.path.join(save_dir, filename)
        with open(file_path, "wb") as buffer:
            content = await audio_file.read()
            buffer.write(content)
        
        return file_path
        
    except Exception as e:
        print(f"íŒŒì¼ ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return None

