From b35b8bce0ed0dd50c1ed27a0eb68c0610461540b Mon Sep 17 00:00:00 2001
From: starwarrior77 <kkk792100@naver.com>
Date: Tue, 17 Jun 2025 14:24:07 +0900
Subject: [PATCH 18/33] =?UTF-8?q?=EB=85=B9=EC=9D=8C=20=EC=82=B4=EC=A7=9D?=
 =?UTF-8?q?=20=EC=88=98=EC=A0=95?=
MIME-Version: 1.0
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 8bit

---
 client/src/components/PoseMiniWidget.vue | 199 +++++++++++++++++++----
 1 file changed, 163 insertions(+), 36 deletions(-)

diff --git a/client/src/components/PoseMiniWidget.vue b/client/src/components/PoseMiniWidget.vue
index 6c15099..e8b871f 100644
--- a/client/src/components/PoseMiniWidget.vue
+++ b/client/src/components/PoseMiniWidget.vue
@@ -11,13 +11,13 @@
     <canvas
       ref="canvas"
       width="1280" height="720"
-      style="position:absolute; top:0; left:0; width:100%; height:100%; z-index:10; pointer-events:none; background:transparent;"
+      style="position:absolute; top:0; left:0; width:100%; height:100%; z-index:100; pointer-events:none; background:transparent; border: 2px solid red;"
     ></canvas>
   </div>
 </template>
 
 <script setup>
-import { ref, onMounted, onBeforeUnmount, defineProps, watch, defineEmits } from 'vue'
+import { ref, onMounted, onBeforeUnmount, defineProps, watch, defineEmits, defineExpose } from 'vue'
 import * as faceapi from 'face-api.js'
 
 const props = defineProps({
@@ -35,9 +35,14 @@ const props = defineProps({
 
 const emit = defineEmits(['updateNonverbalData'])
 
-// ë…¹ìŒ ê´€ë ¨ ìƒíƒœ
-const mediaRecorder = ref(null)
-const audioChunks = ref([])
+// ë¶€ëª¨ ì»´í¬ë„ŒíŠ¸ì—ì„œ ì ‘ê·¼ ê°€ëŠ¥í•˜ë„ë¡ ëˆ„ì  ë°ì´í„° ë…¸ì¶œ
+defineExpose({
+  getAccumulatedNonverbalData: () => accumulatedNonverbalData.value,
+  getCurrentNonverbalData: () => nonverbalData.value
+})
+
+// ë…¹ìŒ ê´€ë ¨ ìƒíƒœ - ë©´ì ‘ìë³„ ê°œë³„ ê´€ë¦¬
+const recorderMap = ref({})  // { [id]: { mediaRecorder, audioChunks, stream } }
 const MOUTH_CLOSED_THRESHOLD = 3000 // 3ì´ˆ
 
 const video = ref(null)
@@ -57,6 +62,9 @@ const faceStates = ref([])
 // ë¹„ì–¸ì–´ì  ë°ì´í„° ì €ì¥ì†Œ
 const nonverbalData = ref({})
 
+// ë©´ì ‘ ì¢…ë£Œ ì‹œ ëˆ„ì  ë°ì´í„° ì €ì¥ì†Œ
+const accumulatedNonverbalData = ref({})  // { [id]: { facial_expression_history: [], posture_history: [], ... } }
+
 // 1ì´ˆë§ˆë‹¤ ë°ì´í„° ì—…ë°ì´íŠ¸ ë° ì „ì†¡
 let updateInterval = null
 
@@ -71,6 +79,16 @@ watch(() => props.intervieweeNames, (newNames) => {
       gesture: 0,
       timestamp: Date.now()
     }
+    
+    // ëˆ„ì  ë°ì´í„° ì´ˆê¸°í™”
+    accumulatedNonverbalData.value[id] = {
+      facial_expression_history: [],
+      posture_history: [],
+      gaze_history: [],
+      gesture_history: [],
+      start_time: Date.now()
+    }
+    
     return {
       name,
       id,
@@ -78,6 +96,7 @@ watch(() => props.intervieweeNames, (newNames) => {
       mouthClosedStartTime: null,
       isRecording: false,
       expression: Object.fromEntries(expList.map(e => [e, 0])),
+      expressionTotal: 0, // ì´ í”„ë ˆì„ ìˆ˜
       lastExpression: null
     }
   })
@@ -117,19 +136,19 @@ async function startRecording(personIndex) {
       return
     }
     
-    mediaRecorder.value = new MediaRecorder(stream, {
+    const recorder = new MediaRecorder(stream, {
       mimeType: mimeType
     })
-    audioChunks.value = []
+    const audioChunks = []
     
-    mediaRecorder.value.ondataavailable = (event) => {
-      audioChunks.value.push(event.data)
-      console.log(`[ë…¹ìŒ ë°ì´í„°] ${state.name}ë‹˜ì˜ ë…¹ìŒ ë°ì´í„° ì²­í¬ ìˆ˜ì‹  (${audioChunks.value.length}ê°œ)`)
+    recorder.ondataavailable = (event) => {
+      audioChunks.push(event.data)
+      console.log(`[ë…¹ìŒ ë°ì´í„°] ${state.name}ë‹˜ì˜ ë…¹ìŒ ë°ì´í„° ì²­í¬ ìˆ˜ì‹  (${audioChunks.length}ê°œ)`)
     }
     
-    mediaRecorder.value.onstop = async () => {
+    recorder.onstop = async () => {
       console.log(`[ë…¹ìŒ ì¢…ë£Œ] ${state.name}ë‹˜ì˜ ë…¹ìŒì´ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. íŒŒì¼ ë³€í™˜ ì¤‘...`)
-      const audioBlob = new Blob(audioChunks.value, { type: mimeType })
+      const audioBlob = new Blob(audioChunks, { type: mimeType })
       const timestamp = new Date().toISOString().replace(/[:.]/g, '-')
       const fileName = `${state.id}_${timestamp}.webm`
       
@@ -158,8 +177,8 @@ async function startRecording(personIndex) {
         console.error(`[ì—…ë¡œë“œ ì‹¤íŒ¨] ${state.name}ë‹˜ì˜ ë…¹ìŒ íŒŒì¼ ì—…ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ:`, error.message)
         state.isRecording = false
       } finally {
-        if (mediaRecorder.value && mediaRecorder.value.stream) {
-          mediaRecorder.value.stream.getTracks().forEach(track => {
+        if (recorder && recorder.stream) {
+          recorder.stream.getTracks().forEach(track => {
             track.stop()
             console.log(`[ë¦¬ì†ŒìŠ¤ ì •ë¦¬] ${state.name}ë‹˜ì˜ ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ íŠ¸ë™ì´ ì •ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤.`)
           })
@@ -167,9 +186,11 @@ async function startRecording(personIndex) {
       }
     }
     
-    mediaRecorder.value.start()
+    recorder.start()
     state.isRecording = true
     console.log(`[ë…¹ìŒ ì‹œì‘] ${state.name}ë‹˜ì˜ ë…¹ìŒì´ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤.`)
+
+    recorderMap.value[state.id] = { mediaRecorder: recorder, audioChunks, stream }
   } catch (error) {
     console.error(`[ë…¹ìŒ ì‹œì‘ ì‹¤íŒ¨] ${state.name}ë‹˜ì˜ ë…¹ìŒ ì‹œì‘ ì¤‘ ì˜¤ë¥˜ ë°œìƒ:`, error.message)
   }
@@ -185,13 +206,14 @@ function stopRecording(personIndex) {
     return
   }
   
-  if (!mediaRecorder.value) {
+  if (!recorderMap.value[state.id]) {
     console.error(`[ë…¹ìŒ ì¢…ë£Œ ì‹¤íŒ¨] ${state.name}ë‹˜ì˜ MediaRecorderê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.`)
     return
   }
   
   try {
-    mediaRecorder.value.stop()
+    const recorder = recorderMap.value[state.id].mediaRecorder
+    recorder.stop()
     state.isRecording = false
     console.log(`[ë…¹ìŒ ì¢…ë£Œ ìš”ì²­] ${state.name}ë‹˜ì˜ ë…¹ìŒ ì¢…ë£Œê°€ ìš”ì²­ë˜ì—ˆìŠµë‹ˆë‹¤.`)
   } catch (error) {
@@ -252,12 +274,41 @@ onMounted(async () => {
       console.log('ì¹´ë©”ë¼ ìŠ¤íŠ¸ë¦¼ íšë“ ì™„ë£Œ')
       
       video.value.srcObject = stream
+      
+      // ë¹„ë””ì˜¤ ë©”íƒ€ë°ì´í„° ë¡œë“œ ì™„ë£Œ í›„ ìº”ë²„ìŠ¤ í¬ê¸° ë™ê¸°í™”
       await new Promise((resolve, reject) => {
         if (!video.value) {
           reject(new Error('ë¹„ë””ì˜¤ ì—˜ë¦¬ë¨¼íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.'))
           return
         }
-        video.value.onloadedmetadata = resolve
+        video.value.onloadedmetadata = () => {
+          console.log('ë¹„ë””ì˜¤ ì‹¤ì œ í•´ìƒë„:', video.value.videoWidth, video.value.videoHeight)
+          // ğŸ’¡ ì‹¤ì œ ë¹„ë””ì˜¤ í•´ìƒë„ë¥¼ ê¸°ë°˜ìœ¼ë¡œ canvas í•´ìƒë„ ì„¤ì • (ìŠ¤ì¼€ì¼ë§ ë¬¸ì œ í•´ê²°)
+          const width = video.value.videoWidth
+          const height = video.value.videoHeight
+          canvas.value.width = width
+          canvas.value.height = height
+          
+          // Canvas ìŠ¤íƒ€ì¼ ë™ì  ì„¤ì •
+          canvas.value.style.zIndex = '100'
+          canvas.value.style.position = 'absolute'
+          canvas.value.style.top = '0'
+          canvas.value.style.left = '0'
+          canvas.value.style.width = '100%'
+          canvas.value.style.height = '100%'
+          canvas.value.style.pointerEvents = 'none'
+          canvas.value.style.background = 'transparent'
+          
+          console.log(`Canvas í•´ìƒë„ ë™ê¸°í™” ì™„ë£Œ: ${width}x${height}`)
+          
+          // í…ŒìŠ¤íŠ¸ìš© ë¹¨ê°„ ì‚¬ê°í˜• ê·¸ë¦¬ê¸°
+          const ctx = canvas.value.getContext('2d')
+          ctx.fillStyle = 'red'
+          ctx.fillRect(20, 20, 50, 50)
+          console.log('í…ŒìŠ¤íŠ¸ìš© ë¹¨ê°„ ì‚¬ê°í˜• ê·¸ë¦¬ê¸° ì™„ë£Œ')
+          
+          resolve()
+        }
         video.value.onerror = reject
       })
       console.log('ë¹„ë””ì˜¤ ë©”íƒ€ë°ì´í„° ë¡œë“œ ì™„ë£Œ')
@@ -275,8 +326,16 @@ onMounted(async () => {
 
       try {
         const ctx = canvas.value.getContext('2d')
-        ctx.clearRect(0, 0, 1280, 720)
-        ctx.drawImage(video.value, 0, 0, 1280, 720)
+        const width = canvas.value.width
+        const height = canvas.value.height
+        
+        ctx.clearRect(0, 0, width, height)
+        ctx.drawImage(video.value, 0, 0, width, height)
+
+        // í…ŒìŠ¤íŠ¸ìš© ì  ì°ê¸° (ê³„ì† ê·¸ë¦¬ê¸°)
+        ctx.fillStyle = 'red'
+        ctx.fillRect(10, 10, 10, 10)
+        ctx.fillRect(width - 20, height - 20, 10, 10) // ìš°í•˜ë‹¨ì—ë„ ì  ì°ê¸°
 
         let detections = await faceapi.detectAllFaces(video.value, new faceapi.TinyFaceDetectorOptions())
           .withFaceLandmarks()
@@ -285,7 +344,7 @@ onMounted(async () => {
         // ë©´ì ‘ì ìˆ˜ì— ë”°ë¼ ê°ì§€ëœ ì–¼êµ´ ìˆ˜ ì œí•œ
         detections = detections.slice(0, props.intervieweeNames.length)
         detections.sort((a, b) => a.detection.box.x - b.detection.box.x)
-
+        console.log('ë¹„ë””ì˜¤ í•´ìƒë„:', video.value.videoWidth, video.value.videoHeight)
         if (detections.length > 0) {
           console.log(`ê°ì§€ëœ ì–¼êµ´ ìˆ˜: ${detections.length}`)
         }
@@ -295,6 +354,13 @@ onMounted(async () => {
           const det = detections[k]
           const color = k === 0 ? 'lime' : k === 1 ? 'yellow' : 'aqua'
           
+          // faceStates ì•ˆì „ì„± ì²´í¬
+          if (!faceStates.value[k]) {
+            console.warn(`faceStates[${k}]ê°€ ì •ì˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ê±´ë„ˆëœë‹ˆë‹¤.`)
+            continue
+          }
+          const faceState = faceStates.value[k]
+          
           // ì–¼êµ´ ëœë“œë§ˆí¬ ì‹œê°í™”
           for (const pt of det.landmarks.positions) {
             ctx.beginPath()
@@ -307,16 +373,30 @@ onMounted(async () => {
           const box = det.detection.box
           ctx.strokeStyle = color
           ctx.lineWidth = 2
-          ctx.strokeRect(box.x, box.y, box.width, box.height)
+          ctx.strokeRect(
+            box.x,
+            box.y,
+            box.width,
+            box.height
+          )
+          console.log(`[ë””ë²„ê·¸] ë°•ìŠ¤ ì¢Œí‘œ(${k}):`, {
+            x: box.x,
+            y: box.y,
+            width: box.width,
+            height: box.height
+          })
           
           // ë©´ì ‘ì ì´ë¦„ í‘œì‹œ
           ctx.font = 'bold 20px sans-serif'
           ctx.fillStyle = color
-          ctx.fillText(faceStates.value[k].name, box.x, box.y - 8)
+          ctx.fillText(
+            faceState.name,
+            box.x,
+            box.y - 8
+          )
 
           // ì…ë²Œë¦¼ ê°ì§€ ë° ë…¹ìŒ ì²˜ë¦¬
           const isSpeaking = detectSpeaking(det.landmarks)
-          const faceState = faceStates.value[k]
           
           if (isSpeaking) {
             if (!faceState.speaking) {
@@ -345,6 +425,7 @@ onMounted(async () => {
           const expKor = expKorean[expLabel]
           if (expKor && expList.includes(expKor)) {
             faceState.expression[expKor]++
+            faceState.expressionTotal++
             faceState.lastExpression = expKor
           }
         }
@@ -371,18 +452,49 @@ onMounted(async () => {
     const currentData = {}
     faceStates.value.forEach((state, index) => {
       const id = props.intervieweeIds[index]
-      currentData[id] = {
+      
+      // í‘œì • ë¹„ìœ¨ ê³„ì‚° (ì´ í”„ë ˆì„ ëŒ€ë¹„)
+      const totalFrames = state.expressionTotal || 1
+      const expressionRatios = {
+        smile: Math.round((state.expression['ë¯¸ì†Œ'] || 0) / totalFrames * 100),
+        neutral: Math.round((state.expression['ë¬´í‘œì •'] || 0) / totalFrames * 100),
+        frown: Math.round((state.expression['ìš¸ìƒ'] || 0) / totalFrames * 100),
+        angry: Math.round((state.expression['ì°¡ê·¸ë¦¼'] || 0) / totalFrames * 100)
+      }
+      
+      const currentNonverbalData = {
         posture: { upright: 0, leaning: 0, slouching: 0 },  // ìì„¸ ë°ì´í„°ëŠ” ì¶”í›„ ì¶”ê°€
-        facial_expression: {
-          smile: state.expression['ë¯¸ì†Œ'] || 0,
-          neutral: state.expression['ë¬´í‘œì •'] || 0,
-          frown: state.expression['ìš¸ìƒ'] || 0,
-          angry: state.expression['ì°¡ê·¸ë¦¼'] || 0
-        },
+        facial_expression: expressionRatios,
         gaze: 0,  // ì‹œì„  ë°ì´í„°ëŠ” ì¶”í›„ ì¶”ê°€
         gesture: 0,  // ì œìŠ¤ì²˜ ë°ì´í„°ëŠ” ì¶”í›„ ì¶”ê°€
         timestamp: Date.now()
       }
+      
+      currentData[id] = currentNonverbalData
+      
+      // ëˆ„ì  ë°ì´í„°ì— ì €ì¥
+      if (accumulatedNonverbalData.value[id]) {
+        accumulatedNonverbalData.value[id].facial_expression_history.push({
+          ...expressionRatios,
+          timestamp: Date.now()
+        })
+        accumulatedNonverbalData.value[id].posture_history.push({
+          ...currentNonverbalData.posture,
+          timestamp: Date.now()
+        })
+        accumulatedNonverbalData.value[id].gaze_history.push({
+          value: currentNonverbalData.gaze,
+          timestamp: Date.now()
+        })
+        accumulatedNonverbalData.value[id].gesture_history.push({
+          value: currentNonverbalData.gesture,
+          timestamp: Date.now()
+        })
+      }
+      
+      // 1ì´ˆë§ˆë‹¤ í‘œì • ì¹´ìš´í„° ì´ˆê¸°í™” (ìµœê·¼ 1ì´ˆê°„ì˜ ë°ì´í„°ë§Œ ìœ ì§€)
+      state.expression = Object.fromEntries(expList.map(e => [e, 0]))
+      state.expressionTotal = 0
     })
     nonverbalData.value = currentData
     emit('updateNonverbalData', currentData)
@@ -393,14 +505,29 @@ onBeforeUnmount(() => {
   active = false
   console.log('[ì»´í¬ë„ŒíŠ¸ ì •ë¦¬] PoseMiniWidget ì»´í¬ë„ŒíŠ¸ë¥¼ ì •ë¦¬í•©ë‹ˆë‹¤...')
   
-  // ëª¨ë“  ë©´ì ‘ìì˜ ë…¹ìŒ ì¤‘ì§€
-  faceStates.value.forEach((state, index) => {
-    if (state.isRecording) {
-      console.log(`[ê°•ì œ ì¢…ë£Œ] ${state.name}ë‹˜ì˜ ë…¹ìŒì„ ê°•ì œ ì¢…ë£Œí•©ë‹ˆë‹¤.`)
-      stopRecording(index)
+  // ëª¨ë“  ë©´ì ‘ìì˜ ë…¹ìŒ ì¤‘ì§€ ë° ë¦¬ì†ŒìŠ¤ ì •ë¦¬
+  Object.entries(recorderMap.value).forEach(([id, recorderData]) => {
+    if (recorderData.mediaRecorder && recorderData.mediaRecorder.state !== 'inactive') {
+      console.log(`[ê°•ì œ ì¢…ë£Œ] ë©´ì ‘ì ID ${id}ì˜ ë…¹ìŒì„ ê°•ì œ ì¢…ë£Œí•©ë‹ˆë‹¤.`)
+      try {
+        recorderData.mediaRecorder.stop()
+      } catch (error) {
+        console.warn(`[ë¦¬ì†ŒìŠ¤ ì •ë¦¬] ë©´ì ‘ì ID ${id}ì˜ ë…¹ìŒ ì¢…ë£Œ ì¤‘ ì˜¤ë¥˜:`, error.message)
+      }
+    }
+    
+    // ìŠ¤íŠ¸ë¦¼ ë¦¬ì†ŒìŠ¤ ì •ë¦¬
+    if (recorderData.stream) {
+      recorderData.stream.getTracks().forEach(track => {
+        track.stop()
+        console.log(`[ë¦¬ì†ŒìŠ¤ ì •ë¦¬] ë©´ì ‘ì ID ${id}ì˜ ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ íŠ¸ë™ì´ ì •ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤.`)
+      })
     }
   })
   
+  // recorderMap ì´ˆê¸°í™”
+  recorderMap.value = {}
+  
   console.log('[ì»´í¬ë„ŒíŠ¸ ì •ë¦¬ ì™„ë£Œ] PoseMiniWidget ì»´í¬ë„ŒíŠ¸ê°€ ì •ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤.')
 
   if (updateInterval) {
-- 
2.39.5 (Apple Git-154)

